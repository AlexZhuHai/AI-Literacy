# 解密大模型：生成式 AI 究竟是如何思考的

## 目录
- 章节1　大模型本质与核心架构
- 章节2　三阶段训练流水线
- 章节3　关键局限与风险
- 章节4　未来趋势：多模态与智能体
- 章节5　课程总结与行动建议

# 章节1　大模型本质与核心架构

## 什么是“大模型”
- 基于概率的“文字接龙”机器：给定前文，预测下一个 token
- 训练语料覆盖互联网级文本，知识量远超个体人类
- 输出非查库，而是概率生成 → 具备创造性也伴随幻觉风险

## Transformer 与注意力机制
- 2017 年 Google 提出，解决长序列“遗忘”问题
- Self-Attention 计算词级关联权重，动态捕捉语境
- 例：“它”在不同句中准确指代苹果 vs 手机，体现“理解”能力

# 章节2　三阶段训练流水线

## 阶段1：预训练（Pre-training）
- 目标：让模型“博览群书”，习得语言与世界知识
- 数据：海量网页、书籍、代码；算力消耗最大（千卡×月）
- 结果：会续写但不懂指令，可能答非所问

## 阶段2：有监督微调（SFT）
- 人工编写高质量问答对，格式统一、答案准确
- 模型学会“指令遵循”，从续写模式转为对话模式
- 显著降低答非所问概率，为后续对齐打基础

## 阶段3：人类反馈强化学习（RLHF）
- 对同一 prompt 生成多答案，人类排序打分
- 用排序信号训练奖励模型，再反向更新语言模型参数
- 输出对齐人类价值观：安全、有用、礼貌、无害

# 章节3　关键局限与风险

## 幻觉（Hallucination）机理
- 概率模型非数据库，遇知识盲区仍要“接龙”→ 编造事实
- 典型表现：细节丰富却完全虚构，引文、数据、情节均可假
- 应对策略：强制事实核查、引用可溯源资料、交叉验证

## 其他局限
- 无实时性：训练后知识静止，需外部插件补足新信息
- 价值观偏差：RLHF 只能逼近标注员分布，存在文化/群体偏差
- 可解释性低：千亿参数黑箱，行为难以精准预测与调试

# 章节4　未来趋势：多模态与智能体

## 多模态融合
- 从纯文本扩展到图像、音频、视频统一建模
- 场景：看图写作、听音配图、跨模态检索与生成
- 技术核心：共享注意力层 + 模态专用编码器/解码器

## 智能体（Agent）化
- 角色转变：问答助手 → 目标驱动的行动者
- 能力：自主调用搜索、订票、支付 API，完成复杂任务闭环
- 具身智能前奏：数字 Agent 未来可对接机器人，实现物理世界操作

# 章节5　课程总结与行动建议

## 核心要点回顾
- 本质：概率接龙；架构：Transformer + Self-Attention
- 训练三步：预训练→SFT→RLHF；幻觉是概率生成固有特征
- 趋势：多模态感知 + Agent 行动，迈向通用人工智能

## 学习与实践建议
- 使用 AI 时保持“核查”习惯：关键信息必须交叉验证
- 关注多模态工具与 Agent 平台，提前体验工作流自动化
- 深入理解局限，才能在科研、产业中安全有效地集成大模型